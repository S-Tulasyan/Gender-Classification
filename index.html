<html>
	<head>
		<style type="text/css">
			body{font-family: sans-serif;}
			p{display: inline-block;}
			img{display: block;}
			.container{width: 90%;position absolute;margin: auto;}
			.title{position: relative;width: 90%;margin: auto;text-align: center;font-weight: bold;font-size: 25px;padding: 1%;}
			.section{position: relative;width: 90%;margin: auto;padding: 2%;}
			.subsection{position: relative; width: 98%;text-align: justify;padding: 10px;}
			.heading{position: relative; width: 98%;text-align: left;font-size: 25px;font-weight: bold;}
			.text{width: 95%;font-size: 20px;text-align: justify;padding: 10px 0px 10px 0px;}
			.authors{position: relative;width: 80%;margin: auto;padding: 2%;font-style: italic;text-align: center;font-size: 12px;}
			.image{width: 95%;font-size: 25px;text-align: left;}
		</style>
	</head>
	<body>
		<div class="container">
			<div class="title">GENDER CLASSIFICATION FROM SPEECH</div>

			<div class="authors">

				<!-- Start edit here  -->
				<p>Shubham Tulasyan, Roll No.: 150102065, Branch: ECE</p>; &nbsp; &nbsp;
				<p>Chaitanya Nivsarkar, Roll No.: 150108006, Branch: EEE</p>; &nbsp; &nbsp;
				<p>Karan Deshmukh, Roll No.: 150108011, Branch: EEE</p>; &nbsp; &nbsp;
				<p>Ratikant Patil, Roll No.: 150108027, Branch: EEE</p>; &nbsp; &nbsp;
				<!-- Stop edit here -->
			</div>


			<div class="section">
				<div class="heading">Abstract</div>
				<div class="text">
					<!-- Start edit here  -->
					Voice classification goes beyond just the frequency of the voice and thus requires additional feature detection and learning based on these features. We used five different models to get the initial accuracies and then used some ensemble methods such as bagging and feature extraction techniques such as PCA to improve the accuracies.
					<!-- Stop edit here -->
				</div>
			</div>

			<div class="section">
				<div class="heading">1. Introduction</div>
				<div class="text">

					<!-- Start edit here  -->
					Human ear has an excellent mechanism of perceiving the voice. It distinguishes the voice based on factors such as the loudness, frequency, the pitch and the resonating frequency. we will be distinguishing the human voice based on the genders - male or female. We will also be analyzing the be model that distinguishes the voices based on the training models.
					<!-- Stop edit here -->

				</div>

				<div class="subsection">
					<div class="heading">1.1 Introduction to Problem</div>
					<div class="text">

						<!-- Start edit here  -->
						A human ear can distinguish between a male and female voice easily. If we want to teach a machine to do the same then what features of a voice would the machine require to classify ?
						<!-- Stop edit here -->

					</div>
				</div>

				<div class="subsection">
					<div class="heading">1.2 Figure</div>
					<div class="image">

						<!-- Start edit here  -->
						<img src="gender.jpg" alt="This text displays when the image is umavailable" width="300px" height=""/>
						<!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading">1.3 Literature Review</div>
					<div class="text">

						<!-- Start edit here  -->
						<p>1. Introduction to Machine Learning by Ethem Alpaydin was used as a refrence when creating and optimising our models for machine learning.</p><br/>
						<p>2. <a href="https://github.com/primaryobjects/voice-gender">Primry Objects - Voice Gender</a> was used as a refrence when exracting features and creating a dataset.</p><br/>
						<p>3. <a href="https://pandas.pydata.org/pandas-docs/stable/">Pandas documentation</a></p><br/>
						<p>4. <a href="http://vineetahirkar.me/documents/ml_report.pdf">Vineet Ahirkar, Naveen Bansal MS in CS, UMBC, Gender Recognition using Voice</a></p><br/>
						<!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading">1.4 Proposed Approach</div>
					<div class="text">
						Initially we started out with some raw audio files from which we extracted 20 features using a program written in R. We ran random forest on these 20 features and got the 7 most useful features. The features are mean fundamental frequency, 25th Quartile ,standard deviation, Inter Quartile Range, specral flatness, mean frequency, mode frequency. These features were used to train a a voting based classifier that used the predictions made by 5 models along with their probablities to predict the final output. The models are Naieve Bayes, K-nearest neighbours, Support Vector Machine, Logistic Regression, Gradient Boosting Classifier. 
						<ul style="list-style-type:disc">
						<li><b>Mean frequency(meanfreq)</b>: Mean of the mean frequencies obtained in each window of the audio signal, measured in kHz.</li>
						<li><b>Standard Deviation of Frequency(sd)</b>: Standard deviation measures the amount of variation of data. A low standard deviation indicates that the values are close to mean, whereas a high standard deviation indicates that the data is moe spread out. </li>
						<li><b>First Quantile(Q25)</b>: Quantiles are the points dividing range of probability distribution into contiguous intervals with equal probabilities. It is the data value when the standard distribution goes beyond the ﬁrst threshold. It is measured in kHz.</li>
						<li><b>Inter Quantile Range(IQR)</b>: Interquantile Range is the difference between the ﬁrst (lower) and the third (upper) quartile and is measured in KHz. It is a measure of statistical dispersion</li>	
						<li><b>Mean Fundamental Frequency(meanfun)</b>: Average of fundamental frequency measured across acoustic signal.</li>
						<li><b>Spectral Flatness(sfm)</b>: Spectral Flatness is a measure used in digital signal processing to characterize an audio spectrum. It is typically measured in decibels and provides a way to quantify how noise-like a sound is, as opposed to being tone-like. It is given by the ratio of the geometric mean and the arithematic mean of the power spectral density.</li>
						<li><b>Mode Frequency(mode)</b>: Mode frequency is the most frequently occurring frequency in the entire signal.</li>
						</ul>
					<div class="image">
						<img src="accuracies.jpg" alt="This text displays when the image is umavailable" width="600px" height="400px" align="middle">
					</div>
					</div>
				</div>
				<div class="subsection">
					<div class="heading">1.5 Report Organization</div>
					<div class="text">

						<!-- Start edit here  -->
						The report is organized as follows: Problem section describes the problem we are trying to solve, Proposed method section describes different approaches we took to solve the problem, Experiment section describes the overall result and accuracies we got from all the different approaches and overall conclusions are mentioned in conclusion section.
						<!-- Stop edit here -->
					</div>
				</div>
			</div>
			<div class="section">
				<div class="heading">3. Experiments &amp; Results</div>
				<div class="subsection">
					<div class="heading">3.1. Plots</div>
					<div class="image">
						<center><img src="scp1.jpg" alt="This text displays when the image is umavailable" width="900px" height="500px" align="middle"></center>
						<center><img src="scp2.jpg" alt="This text displays when the image is umavailable" width="900px" height="500px" align="middle"></center>
					</div>
					<div class="heading">3.2 Dataset Description</div>
					<div class="text">

						<!-- Start edit here  -->
						<p>In order to analyze gender by voice and speech, a training database was required. A database was built using thousands of samples of male and female voices, each labeled by their gender of male or female. Voice samples were collected from the following resources:</p><br/>
						<p>1) VoxForge Speech Corpus</p><br/>
						<p>2) Kaggle: The kaggle dataset contains 3186 voice samples.</p><br/>
						<p> <a href="https://drive.google.com/open?id=148YYM3JK-9S7YRzJCs4lO1LEMEgevQOG">Testing Dataset</a> was used as a refrence when exracting features and creating a dataset.</p><br/>
						<!-- Stop edit here -->
					
					</div>
				</div>
			</div>
			<div class="section">
				<div class="heading">4. Conclusions</div>
				<div class="subsection">
					<div class="heading">4.1 Summary</div>
					<div class="text">
						<!-- Start edit here  -->
						Five different models were trained to classify a voice sample as male or female. Two different techniques were proposed to reduce the dimensionality of data and voting among all the models was proposed to counter variance. The experimentation on the dataset shows an increase in accuracy for all the proposed methods. Random forest performed best in both the approaches involving dimensionality reduction. Voting among all the models seems to always increase the accuracy which is expected due to reduction in variance.
						<!-- Stop edit here -->
					</div>
				</div>
				<div class="subsection">
					<div class="heading">4.2 Future Extensions</div>
					<div class="text">

						<!-- Start edit here  -->
						The code that we used for here for gender classification can be put to use for many different datasets. The feaure exraction method for an audio signal using tuneR and Seewave libraries of 'R' that we used can also be used for other purposes. For this we will open source the algorithm for the use other similar projects. .
						<!-- Stop edit here -->

					</div>
				</div>
			</div>

		</div>
	</body>
</html>
